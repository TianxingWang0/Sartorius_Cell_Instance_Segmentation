{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThreeModel.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ubwcBmfEbM"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x21yP6Vlf0eH"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ0sRMmHDsLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "faad5613-f65b-4e9a-ea7b-517103f767d0"
      },
      "source": [
        "import shutil\n",
        "shutil.copyfile('/content/drive/MyDrive/annotation.zip', '/content/annotation.zip') \n",
        "shutil.copyfile('/content/drive/MyDrive/image.zip', '/content/image.zip') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/image.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnOqwB6PKtEb"
      },
      "source": [
        "!unzip annotation.zip\n",
        "!unzip image.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSptWHbMf28s"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import scipy\n",
        "import numpy as np\n",
        "\n",
        "train_dir = '/content/image/'\n",
        "\n",
        "#train_dir = '/content/drive/MyDrive/data_road/training/image_2/'\n",
        "# os.path.join(\"/content\",\"drive\", \"live\", \"training\", \"image_2\")+\"/\"   # os.path.join是做连接符，等同于data/train/img\n",
        "\n",
        "#train_label_dir = '/content/drive/MyDrive/data_road/training/gt_image_2/'\n",
        "train_label_dir = '/content/annotation/'\n",
        "# os.path.join(\"/content\",\"drive\", \"data_road\", \"training\", \"gt_image_2\")+\"/\"\n",
        "\n",
        "train_list_dir = os.listdir(train_dir)  # 列出train-image目录下的图片名字, 形如[\"um_000001.png\", ...]\n",
        "train_list_dir.sort()  # sort是排序，使得train_list与train_label_list一一对应\n",
        "\n",
        "train_label_list_dir = os.listdir(train_label_dir)  # 列出train-label目录下的图片名字,形如[\"um_road_000001.png\", ...]\n",
        "train_label_list_dir.sort()\n",
        "\n",
        "assert len(train_list_dir)==len(train_label_list_dir), \"训练的图片与标签数量不一致\"\n",
        "\n",
        "train_filenames = [train_dir + filename for filename in train_list_dir if filename[-3:] == 'png']  # 生成图片路径，形如[\"data/train/img/um_000001.png\"]\n",
        "train_label_filenames = [train_label_dir +\n",
        "                         filename for filename in train_label_list_dir if filename[-3:] == 'png'] # 生成label路径，形如[\"data/train/img/um_road_000001.png\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TkG0UlshFtz"
      },
      "source": [
        "def train_generator():\n",
        "    \"\"\"训练集生成器\"\"\"\n",
        "    # 对之前生成的路径列表用zip打包，生成形如[(\"data/train/img/um_000001.png\", \"data/train/img/um_road_000001.png\"), ....]的列表，然后遍历列表，取出一一对应的图片与label。\n",
        "    for train_file_name, train_label_filename in zip(train_filenames, train_label_filenames):\n",
        "        image, label = handle_data(train_file_name, train_label_filename)\n",
        "        \n",
        "\t\t# 这里第一次取的image, label = \"data/train/img/um_000001.png\", \"data/train/img/um_road_000001.png\"， 第二次往后迭代。用yield返回，这是python的generator的用法\n",
        "        yield image, label\n",
        "\n",
        "def test_generator():\n",
        "    \"\"\"测试集生成器\"\"\"\n",
        "    for test_filename in test_filenames:\n",
        "        image = handle_data(test_filename)\n",
        "\n",
        "        yield image\n",
        "\n",
        "\n",
        "def handle_data(train_filenames, train_label_filenames=None):\n",
        "    \"\"\"对数据做处理\"\"\"\n",
        "    image = cv2.imread(train_filenames)\n",
        "    image = cv2.resize(image, image_shape[::-1])# 因为数据的size都不一样，所以需要统一resize到我们约定的size（160，576）\n",
        "    \n",
        "    # 对影像的处理，去除阴影，这一步可以不做，只是效果会差一些。\n",
        "    image_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "    image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
        "    image = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
        "    \n",
        "    # 对label做处理\n",
        "    if train_label_filenames is not None:\n",
        "        gt_image = cv2.imread(train_label_filenames)\n",
        "        gt_image = cv2.resize(gt_image, image_shape[::-1])\n",
        "\n",
        "        background_color = np.array([255, 0, 0])\n",
        "        gt_bg = np.all(gt_image == background_color, axis=2)\n",
        "        gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
        "        gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
        "    \n",
        "        return np.array(image), gt_image\n",
        "    else:\n",
        "        return np.array(image)\n",
        "\n",
        "\n",
        "\n",
        "# def handle_data(train_filenames, train_label_filenames=None):\n",
        "#     \"\"\"对数据做处理\"\"\"\n",
        "#     image = scipy.misc.imresize(\n",
        "#         scipy.misc.imread(train_filenames), image_shape)  # 因为数据的size都不一样，所以需要统一resize到我们约定的size（160，576）\n",
        "    \n",
        "#     # 对影像的处理，去除阴影，这一步可以不做，只是效果会差一些。\n",
        "#     image_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "#     image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
        "#     image = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
        "\n",
        "# \t对label做处理\n",
        "#     if train_label_filenames is not None:\n",
        "#         gt_image = scipy.misc.imresize(\n",
        "#             scipy.misc.imread(train_label_filenames), image_shape)\n",
        "        \n",
        "#         background_color = np.array([255, 0, 0])\n",
        "#         gt_bg = np.all(gt_image == background_color, axis=2)\n",
        "#         gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
        "#         gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
        "    \n",
        "#         return np.array(image), gt_image\n",
        "#     else:\n",
        "#         return np.array(image)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQhf42rFObPq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image = cv2.imread(train_filenames[0])\n",
        "image_shape = (160, 576)\n",
        "image = cv2.resize(image, image_shape[::-1])# 因为数据的size都不一样，所以需要统一resize到我们约定的size（160，576）\n",
        "\n",
        "gt_image = cv2.imread(train_label_filenames[0])\n",
        "gt_image = cv2.resize(gt_image, image_shape[::-1])\n",
        "\n",
        "background_color = np.array([255, 0, 0])\n",
        "gt_bg = np.all(gt_image == background_color, axis=2)\n",
        "gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
        "gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
        "# print(np.array(image))\n",
        "Result = handle_data(train_filenames[0], train_label_filenames[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ccPZ68KhNtJ"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    train_generator, (tf.float32, tf.float32), (tf.TensorShape([None, None, None]), tf.TensorShape([None, None, None])))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_filenames))  # 打乱数据的顺序，即不按照之前sort的顺序读取\n",
        "train_dataset = train_dataset.batch(5)  # 设置批量，同时训练的数据量。tensorflow模型的输入维度为[batcn, h, w, c]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpRoj3j7hZCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154f4583-c474-40b4-bb1a-f4a1a907dea1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "\n",
        "# 加载模型，参数分别表示\n",
        "vgg16_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(160, 160, 3)))\n",
        "\n",
        "vgg16_model.summary()  # 这一行是为了打印模型结构"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 160, 160, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 160, 160, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 80, 80, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 80, 80, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 80, 80, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 40, 40, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 40, 40, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 20, 20, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 20, 20, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 10, 10, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qeC29xEhppu"
      },
      "source": [
        "# model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.initializers import Constant\n",
        "# from tensorflow.nn import conv2d_transpose\n",
        "\n",
        "def bilinear_upsample_weights(factor, number_of_classes):\n",
        "    \"\"\"初始化权重参数\"\"\"\n",
        "    filter_size = factor*2 - factor%2\n",
        "    factor = (filter_size + 1) // 2\n",
        "    if filter_size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:filter_size, :filter_size]\n",
        "    upsample_kernel = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
        "    weights = np.zeros((filter_size, filter_size, number_of_classes, number_of_classes),\n",
        "                       dtype=np.float32)\n",
        "    for i in range(number_of_classes):\n",
        "        weights[:, :, i, i] = upsample_kernel\n",
        "    return weights\n",
        "  \n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "        self.vgg16_model = self.load_vgg()\n",
        "        \n",
        "        self.conv_test = Conv2D(filters=n_class, kernel_size=(1, 1))  # 分类层\n",
        "        self.deconv_test = Conv2DTranspose(filters=n_class, \n",
        "                        kernel_size=(64, 64),\n",
        "                        strides=(32, 32),\n",
        "                        padding='same',\n",
        "                        activation='sigmoid',\n",
        "                        kernel_initializer=Constant(bilinear_upsample_weights(32, n_class)))  # 上采样层\n",
        "\n",
        "    def call(self, input):\n",
        "      x = self.vgg16_model(input)\n",
        "      x = self.conv_test(x)\n",
        "      x = self.deconv_test(x)\n",
        "      return x\n",
        "\n",
        "    def load_vgg(self):\n",
        "        # 加载vgg16模型，其中注意input_tensor，include_top\n",
        "        vgg16_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(image_shape[0], image_shape[1], 3)))\n",
        "        for layer in vgg16_model.layers[:15]:\n",
        "          layer.trainable = False  # 不训练前15层模型\n",
        "        return vgg16_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTul1CuUSlrG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy\n",
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    train_generator, (tf.float32, tf.float32), (tf.TensorShape([None, None, None]), tf.TensorShape([None, None, None])))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_filenames))\n",
        "train_dataset = train_dataset.batch(10)\n",
        "\n",
        "#model = MyModel(2)  # FCN模型\n",
        "model = DeepLabV3Plus(image_shape[0], image_shape[1], nclasses=2)  # deeplab模型\n",
        "\n",
        "# 在得到模型后，配置compile的参数即可，需要optimizer与loss与评估器。learning_rate一般取0.001或者0.0001较好。\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.compat.v2.nn.softmax_cross_entropy_with_logits,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# fit输入的参数为训练集dataset以及跑的轮数，可自己配置，用colab的gpu跑100轮需要1个小时左右。\n",
        "model.fit(train_dataset, epochs=1)\n",
        "# model.summary()\n",
        "\n",
        "# 保存模型，以便以后在这个模型的基础上训练，或者用这个模型测试时，只需要这一个文件与测试数据集即可，不需要再定义模型。\n",
        "# model.save('weights/fcn8s_20191021.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffk_pyLPh0tO"
      },
      "source": [
        "# import os\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import scipy\n",
        "# import cv2\n",
        "# from skimage import io\n",
        "\n",
        "# num_epochs = 5\n",
        "# train_dataset = tf.data.Dataset.from_generator(\n",
        "#     train_generator, (tf.float32, tf.float32), (tf.TensorShape([None, None, None]), tf.TensorShape([None, None, None])))\n",
        "\n",
        "# train_dataset = train_dataset.shuffle(buffer_size=len(train_filenames))\n",
        "# train_dataset = train_dataset.batch(2)\n",
        "\n",
        "# model = MyModel(2)  # FCN模型\n",
        "\n",
        "# # os.chdir('/content/drive/data_road/weights')\n",
        "# # model = MyModel(2)\n",
        "# # model.build(input_shape = [None,160,576,3])\n",
        "# # model.load_weights('FCN8S_20211126.h5')\n",
        "# # model = DeepLabV3Plus(image_shape[0], image_shape[1], nclasses=2)  # deeplab模型\n",
        "# # model.load_weights('DEEPV3_20211126.h5')\n",
        "\n",
        "# # 在得到模型后，配置compile的参数即可，需要optimizer与loss与评估器。learning_rate一般取0.001或者0.0001较好。\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# model.compile(\n",
        "#     optimizer=optimizer,\n",
        "#     loss=tf.compat.v2.nn.softmax_cross_entropy_with_logits,\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "# # fit输入的参数为训练集dataset以及跑的轮数，可自己配置，用colab的gpu跑100轮需要1个小时左右。\n",
        "# model.fit(train_dataset, num_epochs)\n",
        "# # model.summary()\n",
        "\n",
        "# # # 保存模型，以便以后在这个模型的基础上训练，或者用这个模型测试时，只需要这一个文件与测试数据集即可，不需要再定义模型。\n",
        "# # model.save('weights/FCN8S_20211126.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffuRg3LCpOyx"
      },
      "source": [
        "os.chdir('/content/drive/data_road/')\n",
        "model.save_weights('weights/DEEPV3_20211127.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwk9iVfPmLE",
        "outputId": "89f71cbf-37dc-45ef-b415-f4ee0d3b6887"
      },
      "source": [
        "#model = MyModel(2)\n",
        "model = DeepLabV3Plus(image_shape[0], image_shape[1], nclasses=2)  # deeplab模型\n",
        "os.chdir('/content/drive/MyDrive/Cell')\n",
        "model.build([None, 160, 576, 3])\n",
        "model.load_weights('DeepLabV3.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Building DeepLabv3Plus Network ***\n",
            "*** Output_Shape => (None, 160, 576, 2) ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkf1mpvTkOk-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename = train_filenames[0]\n",
        "#filename = test_filenames[0]\n",
        "img = cv2.imread(filename)\n",
        "ori_image = cv2.resize(img, image_shape[::-1])\n",
        "image = ori_image[np.newaxis,:,:,:].astype(\"float32\")\n",
        "print(image.shape)\n",
        "result = model.predict(image)\n",
        "r = result[0]\n",
        "Re = r[:,:,0]\n",
        "print(Re.shape)\n",
        "r\n",
        "# plt.imshow(Re)\n",
        "# result = model.predict(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "-LoEYvNZQcxf",
        "outputId": "0d9390bf-ca89-4e0e-96de-cc5845cd5a00"
      },
      "source": [
        "filename = train_label_filenames[0]\n",
        "img = cv2.imread(filename)\n",
        "img = cv2.resize(img, image_shape[::-1])\n",
        "print(img.shape)\n",
        "plt.imshow(img[:,:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(160, 576, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7d378c7a10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UflJFu_oql55"
      },
      "source": [
        "# Model 2\n",
        "# model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, Add, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.initializers import Constant\n",
        "# from tensorflow.nn import conv2d_transpose\n",
        "image_shape = (160, 576)\n",
        "def bilinear_upsample_weights(factor, number_of_classes):\n",
        "    filter_size = factor*2 - factor%2\n",
        "    factor = (filter_size + 1) // 2\n",
        "    if filter_size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:filter_size, :filter_size]\n",
        "    upsample_kernel = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
        "    weights = np.zeros((filter_size, filter_size, number_of_classes, number_of_classes),\n",
        "                       dtype=np.float32)\n",
        "    for i in range(number_of_classes):\n",
        "        weights[:, :, i, i] = upsample_kernel\n",
        "    return weights\n",
        "  \n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, NUM_OF_CLASSESS):\n",
        "        super().__init__()\n",
        "        vgg16_model = self.load_vgg()\n",
        "        self.conv1_1 = vgg16_model.layers[1]\n",
        "        self.conv1_2 = vgg16_model.layers[2]\n",
        "        self.pool1 = vgg16_model.layers[3]\n",
        "        #(128,128)\n",
        "        self.conv2_1 = vgg16_model.layers[4]\n",
        "        self.conv2_2 = vgg16_model.layers[5]\n",
        "        self.pool2 = vgg16_model.layers[6]\n",
        "        #(64,64)\n",
        "        self.conv3_1 = vgg16_model.layers[7]\n",
        "        self.conv3_2 = vgg16_model.layers[8]\n",
        "        self.conv3_3 = vgg16_model.layers[9]\n",
        "        self.pool3 =  vgg16_model.layers[10]\n",
        "        #(32,32)\n",
        "        self.conv4_1 = vgg16_model.layers[11]\n",
        "        self.conv4_2 = vgg16_model.layers[12]\n",
        "        self.conv4_3 = vgg16_model.layers[13]\n",
        "        self.pool4 =  vgg16_model.layers[14]\n",
        "        #(16,16)\n",
        "        self.conv5_1 = vgg16_model.layers[15]\n",
        "        self.conv5_2 =  vgg16_model.layers[16]\n",
        "        self.conv5_3 = vgg16_model.layers[17]\n",
        "        self.pool5 = vgg16_model.layers[18]\n",
        "        self.conv6 = Conv2D(4096,(7,7),(1,1),padding=\"same\",activation=\"relu\")\n",
        "        self.drop6 = Dropout(0.5)\n",
        "        self.conv7 = Conv2D(4096,(1,1),(1,1),padding=\"same\",activation=\"relu\")\n",
        "        self.drop7 = Dropout(0.5)\n",
        "        self.score_fr = Conv2D(NUM_OF_CLASSESS,(1,1),(1,1),padding=\"valid\",activation=\"relu\")\n",
        "        self.score_pool4 = Conv2D(NUM_OF_CLASSESS,(1,1),(1,1),padding=\"valid\",activation=\"relu\")\n",
        "        self.conv_t1 = Conv2DTranspose(NUM_OF_CLASSESS,(4,4),(2,2),padding=\"same\")\n",
        "        self.fuse_1 = Add()\n",
        "        self.conv_t2 = Conv2DTranspose(NUM_OF_CLASSESS,(4,4),(2,2),padding=\"same\")\n",
        "        self.score_pool3 = Conv2D(NUM_OF_CLASSESS,(1,1),(1,1),padding=\"valid\",activation=\"relu\")\n",
        "        self.fuse_2 = Add()\n",
        "        self.conv_t3 = Conv2DTranspose(NUM_OF_CLASSESS,(16,16),(8,8),padding=\"same\", activation=\"sigmoid\", kernel_initializer=Constant(bilinear_upsample_weights(8, NUM_OF_CLASSESS)))\n",
        "        \n",
        "\n",
        "    def call(self, input):\n",
        "      x = self.conv1_1(input)\n",
        "      x = self.conv1_2(x)\n",
        "      x = self.pool1(x)\n",
        "      x = self.conv2_1(x)\n",
        "      x = self.conv2_2(x)\n",
        "      x = self.pool2(x)\n",
        "      x = self.conv3_1(x)\n",
        "      x = self.conv3_2(x)\n",
        "      x = self.conv3_3(x)\n",
        "      x_3 = self.pool3(x)\n",
        "      x = self.conv4_1(x_3)\n",
        "      x = self.conv4_2(x)\n",
        "      x = self.conv4_3(x)\n",
        "      x_4 = self.pool4(x)\n",
        "      x = self.conv5_1(x_4)\n",
        "      x = self.conv5_2(x)\n",
        "      x = self.conv5_3(x)\n",
        "      x = self.pool5(x)\n",
        "      x = self.conv6(x)\n",
        "      x = self.drop6(x)\n",
        "      x = self.conv7(x)\n",
        "      x = self.drop7(x)\n",
        "      x = self.score_fr(x)  # 第5层pool分类结果\n",
        "      x_score4 = self.score_pool4(x_4) # 第4层pool分类结果\n",
        "      x_dconv1 = self.conv_t1(x)  # 第5层pool分类结果上采样\n",
        "      x = self.fuse_1([x_dconv1,x_score4])  # 第4层pool分类结果+第5层pool分类结果上采样\n",
        "      x_dconv2 = self.conv_t2(x)  # 第一次融合后上采样\n",
        "      x_score3 = self.score_pool3(x_3)  # 第三次pool分类\n",
        "      x = self.fuse_2([x_dconv2,x_score3])  #  第一次融合后上采样+第三次pool分类\n",
        "      x = self.conv_t3(x)  # 上采样\n",
        "      return x\n",
        "\n",
        "    def load_vgg(self):\n",
        "        # 加载vgg16模型，其中注意input_tensor，include_top\n",
        "        vgg16_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(image_shape[0], image_shape[1], 3)))\n",
        "        for layer in vgg16_model.layers[:18]:\n",
        "          layer.trainable = False\n",
        "        return vgg16_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Mcu136qvQ3"
      },
      "source": [
        "#DeepLabLab V3\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import AveragePooling2D, Lambda, Conv2D, Conv2DTranspose, Activation, Reshape, concatenate, Concatenate, BatchNormalization, ZeroPadding2D\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\n",
        "def Upsample(tensor, size):\n",
        "    '''bilinear upsampling'''\n",
        "    name = tensor.name.split('/')[0] + '_upsample'\n",
        "\n",
        "    def bilinear_upsample(x, size):\n",
        "        resized = tf.image.resize(\n",
        "            images=x, size=size)\n",
        "        return resized\n",
        "    y = Lambda(lambda x: bilinear_upsample(x, size),\n",
        "               output_shape=size, name=name)(tensor)\n",
        "    return y\n",
        "\n",
        "\n",
        "def ASPP(tensor):\n",
        "    '''atrous spatial pyramid pooling'''\n",
        "    dims = K.int_shape(tensor)\n",
        "\n",
        "    y_pool = AveragePooling2D(pool_size=(\n",
        "        dims[1], dims[2]), name='average_pooling')(tensor)\n",
        "    y_pool = Conv2D(filters=256, kernel_size=1, padding='same',\n",
        "                    kernel_initializer='he_normal', name='pool_1x1conv2d', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "\n",
        "    y_pool = Upsample(tensor=y_pool, size=[dims[1], dims[2]])\n",
        "\n",
        "    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same',\n",
        "                 kernel_initializer='he_normal', name='ASPP_conv2d_d1', use_bias=False)(tensor)\n",
        "    y_1 = BatchNormalization(name=f'bn_2')(y_1)\n",
        "    y_1 = Activation('relu', name=f'relu_2')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same',\n",
        "                 kernel_initializer='he_normal', name='ASPP_conv2d_d6', use_bias=False)(tensor)\n",
        "    y_6 = BatchNormalization(name=f'bn_3')(y_6)\n",
        "    y_6 = Activation('relu', name=f'relu_3')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same',\n",
        "                  kernel_initializer='he_normal', name='ASPP_conv2d_d12', use_bias=False)(tensor)\n",
        "    y_12 = BatchNormalization(name=f'bn_4')(y_12)\n",
        "    y_12 = Activation('relu', name=f'relu_4')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same',\n",
        "                  kernel_initializer='he_normal', name='ASPP_conv2d_d18', use_bias=False)(tensor)\n",
        "    y_18 = BatchNormalization(name=f'bn_5')(y_18)\n",
        "    y_18 = Activation('relu', name=f'relu_5')(y_18)\n",
        "\n",
        "    y = concatenate([y_pool, y_1, y_6, y_12, y_18], name='ASPP_concat')\n",
        "\n",
        "    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same',\n",
        "               kernel_initializer='he_normal', name='ASPP_conv2d_final', use_bias=False)(y)\n",
        "    y = BatchNormalization(name=f'bn_final')(y)\n",
        "    y = Activation('relu', name=f'relu_final')(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "def DeepLabV3Plus(img_height, img_width, nclasses=2):\n",
        "    print('*** Building DeepLabv3Plus Network ***')\n",
        "    \n",
        "\t# 这里加载ResNet50模型，并且使用其两个模块的结果。\n",
        "    base_model = ResNet50(input_shape=(\n",
        "        img_height, img_width, 3), weights='imagenet', include_top=False)\n",
        "    \n",
        "    # 可以像模型加载章节的加载部分打印ResNet50模型，查看结构，“conv4_block6_2_relu”为层的名字， 加上.output表示这一层的输出。\n",
        "    image_features = base_model.get_layer('conv4_block6_2_relu').output\n",
        "    x_a = ASPP(image_features)\n",
        "    x_a = Upsample(tensor=x_a, size=[img_height // 4, img_width // 4])\n",
        "\n",
        "    x_b = base_model.get_layer('conv2_block3_2_relu').output\n",
        "    x_b = Conv2D(filters=48, kernel_size=1, padding='same',\n",
        "                 kernel_initializer='he_normal', name='low_level_projection', use_bias=False)(x_b)\n",
        "    x_b = BatchNormalization(name=f'bn_low_level_projection')(x_b)\n",
        "    x_b = Activation('relu', name='low_level_activation')(x_b)\n",
        "\n",
        "    x = concatenate([x_a, x_b], name='decoder_concat')\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',\n",
        "               kernel_initializer='he_normal', name='decoder_conv2d_1', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_decoder_1')(x)\n",
        "    x = Activation('relu', name='activation_decoder_1')(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',\n",
        "               kernel_initializer='he_normal', name='decoder_conv2d_2', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_decoder_2')(x)\n",
        "    x = Activation('relu', name='activation_decoder_2')(x)\n",
        "    x = Upsample(x, [img_height, img_width])\n",
        "\n",
        "    x = Conv2D(nclasses, (1, 1), name='output_layer')(x)\n",
        "    '''\n",
        "    x = Activation('softmax')(x) \n",
        "    tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    Args:\n",
        "        from_logits: Whether `y_pred` is expected to be a logits tensor. By default,\n",
        "        we assume that `y_pred` encodes a probability distribution.\n",
        "    '''     \n",
        "    model = Model(inputs=base_model.input, outputs=x, name='DeepLabV3_Plus')\n",
        "    print(f'*** Output_Shape => {model.output_shape} ***')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}